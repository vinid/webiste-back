---
title: "A Rounded Evaluation of Recommender Systems"
subtitle: "EvalRS: Evaluating Recommender Systems on Many Tests"

# Summary for listings and search engines
summary: "This article describes a novel data and code challenge that is currently running: EvalRS. We decided to organize EvalRS with friends from Coveo, Microsoft, and NVIDIA, to better understand evaluation in Recommender Systems."

# Link this post with a project
projects: [Recommender Systems]

# Date published
date: "2022-08-11T00:00:00Z"

# Date updated
lastmod: "2022-08-11T00:00:00Z"

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: true

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image:
  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/H4fYXZ1hyco)'
  focal_point: ""
  placement: 2
  preview_only: false

authors:
- Federico Bianchi


tags:
- Academic
- AI

categories:
- Recommender Systems

links:
 - name: Read on Medium
   url: https://medium.com/p/b9fa101ef79a

---

## Overview

Recommender Systems are probably one of the most popular machine learning systems in production; moreover, recommenders are probably the machine learning products that have the closest contact with the actual users, since they are generally used in an interactive fashion.

This is why testing is fundamental in Recommender Systems. Failing to detect low performance in some cases can bring reputational damage to a company.

[Read More](https://medium.com/p/b9fa101ef79a)
